# Text-Preprocess
NLP Text Preprocessing using NLTK library


## Tokenization
Tokenization is the process of tokenizing or splitting a string, text into a list of tokens.


## Stemming
Stemming is the process of producing morphological variants of a root/base word.
A stemming algorithm reduces the words “chocolates”, “chocolatey”, and “choco” to the root word, “chocolate”


## Lemmatization
Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.
Lemmatization is similar to stemming but it brings context to the words.
